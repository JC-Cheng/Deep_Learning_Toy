{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 940M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN not available)\n",
      "C:\\toolkits\\anaconda2-4.2.0\\lib\\site-packages\\theano-0.8.2-py2.7.egg\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.datasets import imdb\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from theano import function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This code was borrowed and modified from https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py\n",
    "    \n",
    "Train a LSTM on the IMDB sentiment classification task. The dataset is actually too small for LSTM to be of any advantage compared to simpler, much faster methods such as TF-IDF+LogReg.\n",
    "\n",
    "- Notes:\n",
    "    - RNNs are tricky. Choice of batch size is important, choice of loss and optimizer is critical, etc. Some configurations won't converge.\n",
    "    - LSTM loss decrease patterns during training can be quite different from what you see with CNNs/MLPs/etc.\n",
    "    - Suggested GPU command: THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_lstm.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "20000 train sequences\n",
      "5000 test sequences\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (20000L, 100L)\n",
      "X_test shape: (5000L, 100L)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IMDB Data\n",
    "Sample reviews from the full IMDb movie reviews dataset.\n",
    "\n",
    "Negative review examples:\n",
    "* Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting.\n",
    "* Even those from the era should be turned off.\n",
    "* The cryptic dialogue would make Shakespeare seem easy to a third grader.\n",
    "\n",
    "Positive review examples:\n",
    "* I didn't know this came from Canada, but it is very good. Very good!\n",
    "* I liked this movie a lot. It really intrigued me how Deanna and Alicia became friends over such a tragedy\n",
    "* When I saw the elaborate DVD box for this and the dreadful Red Queen figurine, \n",
    "  I felt certain I was in for a big disappointment, but surprise, surprise, I loved it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 0, 0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  269,   929,    18,     2,     7,     2,  4284,     8,   105,\n",
       "            5,     2,   182,   314,    38,    98,   103,     7,    36,\n",
       "         2184,   246,   360,     7,    19,   396,    17,    26,   269,\n",
       "          929,    18,  1769,   493,     6,   116,     7,   105,     5,\n",
       "          575,   182,    27,     5,  1002,  1085,   130,    62,    17,\n",
       "           24,    89,    17,    13,   381,  1421,     8,  5167,     7,\n",
       "            5,  2723,    38,   325,     7,    17,    23,    93,     9,\n",
       "          156,   252,    19,   235,    20,    28,     5,   104,    76,\n",
       "            7,    17,   169,    35, 14764,    17,    23,  1460,     7,\n",
       "           36,  2184,   934,    56,  2134,     6,    17,   891,   214,\n",
       "           11,     5,  1552,     6,    92,     6,    33,   256,    82,\n",
       "            7],\n",
       "       [   24,    89,    33,  4317,    17,   551,  1851,  3994,    43,\n",
       "           37,   240,    40,   635,     9,   189,   331,  4183,    45,\n",
       "            5,     2,     6,   102,    37,    24,     5,   137,    18,\n",
       "            5,   757,     7,    15,    16,    12,    14,    15,    16,\n",
       "           12,    14,    25,    26,   212,    63,    20,    30,    13,\n",
       "           36,    11,    41,   635,   636,     7,    53,   230,    35,\n",
       "          212,    43,    46,   199,  6843,    26,  2539,    61,  1401,\n",
       "            7,     5,   453,  4693,   231,   112,    40,    93,  4232,\n",
       "           27,     9,  5926,     2,    56,   127,     7,    78,   124,\n",
       "           20,    30,    18,     9,  3245,   617,  2806,     6,   911,\n",
       "           19,    66,    82,    64,   681,  4058,    11,     5,  1324,\n",
       "            7]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "\n",
    "model.add(LSTM(128))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.embeddings.Embedding at 0x654a9f28>,\n",
       " <keras.layers.recurrent.LSTM at 0x654a9f98>,\n",
       " <keras.layers.core.Dropout at 0x654b5208>,\n",
       " <keras.layers.core.Dense at 0x654b5898>,\n",
       " <keras.layers.core.Activation at 0x65559358>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = model.get_input()\n",
    "embedding = model.layers[0].get_output()\n",
    "F = function([inp], embedding, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  269   929    18     2     7     2  4284     8   105     5     2   182\n",
      "    314    38    98   103     7    36  2184   246   360     7    19   396\n",
      "     17    26   269   929    18  1769   493     6   116     7   105     5\n",
      "    575   182    27     5  1002  1085   130    62    17    24    89    17\n",
      "     13   381  1421     8  5167     7     5  2723    38   325     7    17\n",
      "     23    93     9   156   252    19   235    20    28     5   104    76\n",
      "      7    17   169    35 14764    17    23  1460     7    36  2184   934\n",
      "     56  2134     6    17   891   214    11     5  1552     6    92     6\n",
      "     33   256    82     7]]\n",
      "(1L, 100L)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:1])\n",
    "print(X_train[:1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.04523628 -0.04581409  0.00139403 ...,  0.02757302 -0.00659316\n",
      "    0.04097552]\n",
      "  [ 0.01897613 -0.02050843  0.03176945 ...,  0.01020672 -0.04183867\n",
      "    0.01724149]\n",
      "  [ 0.03700239  0.04918102  0.02664101 ..., -0.00773543  0.04357829\n",
      "   -0.02801045]\n",
      "  ..., \n",
      "  [-0.02343854  0.0315331   0.01564403 ...,  0.01475945  0.04115001\n",
      "   -0.01540261]\n",
      "  [-0.04782986  0.03330185 -0.04914759 ...,  0.03126881  0.01868706\n",
      "    0.01558241]\n",
      "  [-0.02831537 -0.01510486  0.01608345 ...,  0.00183296 -0.02324817\n",
      "   -0.03318051]]]\n",
      "(1L, 100L, 128L)\n"
     ]
    }
   ],
   "source": [
    "print(F(X_train[:1]))\n",
    "print(F(X_train[:1]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 92s - loss: 0.4604 - acc: 0.7758 - val_loss: 0.3802 - val_acc: 0.8352\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 91s - loss: 0.2676 - acc: 0.8958 - val_loss: 0.3779 - val_acc: 0.8402\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 97s - loss: 0.1547 - acc: 0.9432 - val_loss: 0.4604 - val_acc: 0.8274\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 98s - loss: 0.0908 - acc: 0.9689 - val_loss: 0.6801 - val_acc: 0.8258\n",
      "5000/5000 [==============================] - 10s    \n",
      "Test score: 0.680139132333\n",
      "Test accuracy: 0.8258\n"
     ]
    }
   ],
   "source": [
    "print(\"Train...\")\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=4,\n",
    "          validation_data=(X_test, y_test), show_accuracy=True)\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, show_accuracy=True)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SGD\n",
    "...Not improve at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\r\n",
      "   Creating library C:/Users/user/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpgrs_5r/a34361e57f0f9e245bb592780ca46e94.lib and object C:/Users/user/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64/tmpgrs_5r/a34361e57f0f9e245bb592780ca46e94.exp\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_sgd = Sequential()\n",
    "model_sgd.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "\n",
    "model_sgd.add(LSTM(128))\n",
    "model_sgd.add(Dropout(0.5))\n",
    "model_sgd.add(Dense(1))\n",
    "model_sgd.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_sgd.compile(loss='binary_crossentropy', optimizer=sgd, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 95s - loss: 0.3191 - acc: 0.8682 - val_loss: 0.3755 - val_acc: 0.8310\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 86s - loss: 0.2400 - acc: 0.9056 - val_loss: 0.4051 - val_acc: 0.8350\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 88s - loss: 0.1755 - acc: 0.9362 - val_loss: 0.4549 - val_acc: 0.8342\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 89s - loss: 0.1233 - acc: 0.9599 - val_loss: 0.5490 - val_acc: 0.8312\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 86s - loss: 0.0832 - acc: 0.9746 - val_loss: 0.6569 - val_acc: 0.8328\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 93s - loss: 0.0655 - acc: 0.9797 - val_loss: 0.6555 - val_acc: 0.8264\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 103s - loss: 0.0493 - acc: 0.9853 - val_loss: 0.7365 - val_acc: 0.8288\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 89s - loss: 0.0344 - acc: 0.9898 - val_loss: 0.8699 - val_acc: 0.8228\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 95s - loss: 0.0284 - acc: 0.9922 - val_loss: 0.8216 - val_acc: 0.8224\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 88s - loss: 0.0256 - acc: 0.9926 - val_loss: 1.0140 - val_acc: 0.8202\n",
      "5000/5000 [==============================] - 9s     \n",
      "Test score: 1.01398169923\n",
      "Test accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "print(\"Train...\")\n",
    "\n",
    "model_sgd.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10,\n",
    "          validation_data=(X_test, y_test), show_accuracy=True)\n",
    "score, acc = model_sgd.evaluate(X_test, y_test, batch_size=batch_size, show_accuracy=True)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
